# Buscador de Subvenciones (Orellana)

<div style="text-align: center;">
  <img src="media/logo.png" alt="alt text" style="width: 250px;" />
</div>

Orellana es una **aplicaciÃ³n web** de chat conversacional para buscar informaciÃ³n sobre subvenciones (convocatorias, beneficiarios, etc.) en EspaÃ±a usando servicios de IA y una arquitectura basada en grafos.

## ðŸ“‹ DescripciÃ³n

- **Lenguaje**: Python 3.10+
- **Framework Web**: Flask
- **Motor de IA**: Gemini (a travÃ©s de `langgraph`) y OpenAI
- **Arquitectura**: Orquestador basado en grafos (LangGraph) con agentes especializados y microservicios (MCP).
- **Frontend**: HTML/CSS/JS mÃ­nimo, sin frameworks de JS

El objetivo es proporcionar una interfaz de chat donde el usuario haga consultas en lenguaje natural y obtenga respuestas detalladas sobre subvenciones, parÃ¡metros de bÃºsqueda, detalles de convocatoria y listados de beneficiarios.

---

## ðŸ”§ Requisitos

- Python 3.10 o superior
- Acceso a la API de InfoSubvenciones (URL y credenciales en `.env`)
- Claves de API de IA (configuraciÃ³n en `.env`)

InstalaciÃ³n de dependencias:
```bash
pip install -r requirements.txt
```

## âš™ï¸ ConfiguraciÃ³n

1. Copiar `.env.example` a `.env`:
   ```bash
   cp .env.example .env
   ```
2. Rellenar variables en `.env`:
   ```dotenv
   PORT=5000
   FLASK_DEBUG=True
   INFOSUBVENCIONES_API_URL=https://api.infosubvenciones.gob.es
   INFOSUBVENCIONES_API_KEY=TU_API_KEY
   GEMINI_API_KEY=TU_API_KEY_GEMINI
   GEMINI_MODEL=gemini-1.5-flash # O el modelo que desees usar
   ```

---

## ðŸ“‚ Estructura de Directorios

```text
buscador_subvenciones_codigo/
â”œâ”€ .env
â”œâ”€ requirements.txt
â”œâ”€ prompts/                   # Plantillas para llamadas a modelos de IA
â”‚  â”œâ”€ ... (prompts)
â”œâ”€ src/
â”‚  â”œâ”€ main.py                # Entrada de la aplicaciÃ³n Flask
â”‚  â”œâ”€ agents/                # Agentes LLM: extracciÃ³n, API, generaciÃ³n, errores
â”‚  â”œâ”€ services/              # Servicios: llamadas a API, estado de grafo, helpers
â”‚  â”œâ”€ graph/                 # DefiniciÃ³n de grafo de flujo de trabajo con LangGraph
â”‚  â”œâ”€ templates/
â”‚  â”‚   â””â”€ index.html         # Plantilla de la interfaz de usuario
â”‚  â””â”€ static/
â”‚      â”œâ”€ css/styles.css
â”‚      â””â”€ js/main.js
â”œâ”€ tools/                     # Herramientas y microservicios externos
â”‚  â””â”€ info_convocatoria_mcp.py # Servidor MCP para scraping y resumen de convocatorias
```

---

## ðŸ›ï¸ Arquitectura & Flujo de EjecuciÃ³n

1.  **Usuario** accede a la ruta `/` y carga `index.html`, que inicializa el chat.
2.  El cliente JS envÃ­a la consulta al endpoint `/api/chat` vÃ­a `fetch`.
3.  En `main.py`, se crea un objeto `GraphState` con la consulta original y el historial.
4.  Se construye el **grafo de flujo** definido en `src/graph/graph.py`:
    -   Nodos de **determinaciÃ³n de intenciÃ³n** y **extracciÃ³n de parÃ¡metros**.
    -   Nodos de **llamada a APIs** (`infosubvenciones_service`) y **herramientas externas**, como el microservicio de scraping (`info_convocatoria_mcp.py`).
    -   Nodos de **generaciÃ³n de respuestas** con IA.
    -   Nodos de **manejo de errores**.
5.  El grafo evalÃºa condiciones en cada arista para decidir la siguiente acciÃ³n.
6.  Los **Agentes** (`src/agents/*.py`) ejecutan las tareas correspondientes.
7.  Si se necesita informaciÃ³n de una URL externa (p. ej., el detalle de una convocatoria), un agente puede invocar a la herramienta **`info_convocatoria_mcp.py`**, que se ejecuta como un servidor independiente.
8.  El resultado final es **streamed** al cliente, que renderiza los mensajes en la interfaz.

---

## ðŸ› ï¸ Detalle de Componentes

A continuaciÃ³n se describen con mÃ¡s detalle los principales ficheros Python del proyecto.

### 1. `src/main.py` (AplicaciÃ³n Flask)
- **Punto de entrada** de la aplicaciÃ³n web principal.
- Define la ruta `/api/chat` que recibe las consultas del usuario e invoca el grafo de LangGraph para procesarlas.
- Gestiona el streaming de la respuesta de vuelta al cliente.

---

### 2. Agentes (`src/agents/*.py`)
Cada agente es una clase con un mÃ©todo `run` que modifica el estado del grafo.
-   **ExtractorAgent**: Extrae parÃ¡metros (aÃ±os, IDs) de la consulta del usuario.
-   **ApiCallerAgent**: Realiza llamadas a APIs externas, como InfoSubvenciones o el microservicio de scraping.
-   **GeneratorAgent**: Genera la respuesta en lenguaje natural usando un LLM.
-   **BeneficiariesAgent**: Formatea listas de beneficiarios.
-   **ErrorHandlerAgent**: Gestiona excepciones y errores durante la ejecuciÃ³n.

---

### 3. Servicios (`src/services/*.py`)
-   **`infosubvenciones_service.py`**: Encapsula la lÃ³gica para interactuar con la API de InfoSubvenciones.
-   **`langgraph_service.py`**: Orquesta la ejecuciÃ³n del grafo definido con LangGraph.
-   **`graph_state.py`**: Define la estructura de datos (`GraphState`) que fluye a travÃ©s del grafo.
-   **`gemini_helpers.py`**: Funciones auxiliares para interactuar con la API de Gemini.

---

### 4. Grafo de ConversaciÃ³n (`src/graph/graph.py`)
- Define la lÃ³gica de control del chatbot.
- Conecta los agentes mediante nodos y aristas condicionales para crear flujos de conversaciÃ³n complejos y adaptativos.

---

### 5. Frontend (`src/templates` y `src/static`)
- Contiene el cÃ³digo HTML, CSS y JavaScript para la interfaz de chat del usuario.
- Se comunica con el backend a travÃ©s de peticiones `fetch` y maneja respuestas en streaming (Server-Sent Events).

---

### 6. Herramienta de Scraping (`tools/info_convocatoria_mcp.py`)
Este script funciona como un **microservicio independiente** para extraer y resumir informaciÃ³n detallada de pÃ¡ginas de convocatorias.

-   **TecnologÃ­a**: Se basa en `FastMCP` para crear un servidor de herramientas ligero.
-   **PropÃ³sito**: Ofrecer una funciÃ³n (`get_info_convo`) que, dada una URL, extrae no solo el contenido de la pÃ¡gina, sino tambiÃ©n el texto de cualquier documento PDF enlazado.
-   **Flujo de trabajo interno**:
    1.  Recibe una URL.
    2.  Utiliza `requests` y `BeautifulSoup` para descargar y parsear el HTML de la pÃ¡gina.
    3.  Identifica todos los enlaces que apuntan a ficheros PDF.
    4.  Descarga cada PDF y extrae su contenido de texto usando `PyPDF2`.
    5.  Combina el texto de la pÃ¡gina web y el de los PDFs en un Ãºnico documento.
    6.  EnvÃ­a este documento combinado al modelo de Gemini (`summarise_via_llm`) para obtener un resumen conciso.
    7.  Devuelve el resumen como resultado.
-   **EjecuciÃ³n**: Se debe ejecutar en un terminal separado para que estÃ© disponible para la aplicaciÃ³n principal.
    ```bash
    python tools/info_convocatoria_mcp.py
    ```

---

## ðŸ“ˆ Organigrama de la OrganizaciÃ³n de Agentes

El siguiente diagrama muestra el flujo de datos y la interacciÃ³n entre los componentes clave del sistema, incluyendo la nueva herramienta de scraping.

```mermaid
graph TD
    subgraph "AplicaciÃ³n Principal (Flask + LangGraph)"
        U[Usuario]
        E[ExtractorAgent]
        A[ApiCallerAgent]
        G[GeneratorAgent]
        B[BeneficiariesAgent]
        H[ErrorHandlerAgent]
    end

    subgraph "Microservicios Externos"
        MCP[Scraper Service /tools/info_convocatoria_mcp.py]
    end

    U -->|Consulta| E
    E -->|ParÃ¡metros extraÃ­dos| A
    A -->|URL de convocatoria| MCP
    A -->|API InfoSubvenciones| G
    MCP -->|Resumen de la convocatoria y PDFs| A
    A -->|Datos enriquecidos| G
    G -->|Respuesta parcial| B
    B -->|Beneficiarios formateados| G
    G -->|Respuesta final| U

    %% Rutas de errores
    E -->|Error| H
    A -->|Error| H
    MCP -->|Error| H
    G -->|Error| H
    H -->|Mensaje de error| U
```